{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "#!git clone https://github.com/facebookresearch/pytorchvideo.git\n",
    "#!pip install fvcore\n",
    "#!pip install albumentations\n",
    "#!pip install albumentations.pytorch\n",
    "#!pip install transformers"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import torch\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import glob2\n",
    "import cv2\n",
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from argparse import Namespace\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, IterableDataset\n",
    "import albumentations\n",
    "import albumentations.pytorch\n",
    "from transformers.optimization import AdamW, get_cosine_schedule_with_warmup\n",
    "from transformers import set_seed\n",
    "import pytorchvideo.models.hub as pyvideo\n",
    "!nvidia-smi\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"0\"\n",
    "\n",
    "\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Tue Oct 19 09:03:22 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.80.02    Driver Version: 450.80.02    CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-PCIE...  Off  | 00000000:18:00.0 Off |                    0 |\n",
      "| N/A   49C    P0    39W / 250W |   1181MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-PCIE...  Off  | 00000000:AF:00.0 Off |                    0 |\n",
      "| N/A   56C    P0    46W / 250W |  25403MiB / 32510MiB |     30%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "random_seed = 42\n",
    "set_seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed_all(random_seed) # if use multi-GPU\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(random_seed)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "opt = {\n",
    "    \"batch_size\": 4,\n",
    "    \"num_workers\": 1,\n",
    "    \"lr\": 5e-5,\n",
    "    \"max_epochs\": 60,\n",
    "    \"warmup_ratio\": 0.2,\n",
    "    \"print_step\": 100,\n",
    "    \"save_path\": \"model_weights\",\n",
    "} \n",
    "args = Namespace(**opt)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "class LabelSmoothingLoss(nn.Module):\n",
    "    def __init__(self, classes, smoothing=0.0, dim=-1):\n",
    "        super(LabelSmoothingLoss, self).__init__()\n",
    "        self.confidence = 1.0 - smoothing\n",
    "        self.smoothing = smoothing\n",
    "        self.cls = classes\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        pred = pred.log_softmax(dim=self.dim)\n",
    "        with torch.no_grad():\n",
    "            # true_dist = pred.data.clone()\n",
    "            true_dist = torch.zeros_like(pred)\n",
    "            true_dist.fill_(self.smoothing / (self.cls - 1))\n",
    "            true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
    "        return torch.mean(torch.sum(-true_dist * pred, dim=self.dim))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "class ActionBasicModule(nn.Module):\n",
    "    def __init__(self, device=\"cpu\", net=None):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.model = net\n",
    "        self.model.blocks[6].proj = nn.Linear(self.model.blocks[6].proj.in_features, 6, bias=True)\n",
    "        #self.model = self.model.to(self.device)\n",
    "        \n",
    "\n",
    "    def forward(self, x, label=None, loss_mode=\"smoothin\", smoothing=0.0):\n",
    "        x = self.model(x)\n",
    "        if label is not None:\n",
    "            if loss_mode == \"smoothing\":\n",
    "                lossFunc = LabelSmoothingLoss(6, smoothing=smoothing).to(self.device)\n",
    "            else:\n",
    "                lossFunc = nn.CrossEntropyLoss().to(self.device)\n",
    "            label = label.to(self.device)    \n",
    "            loss = lossFunc(x, label)\n",
    "            return x, loss\n",
    "        return x, _"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "device = \"cuda\"\n",
    "mean = [0.45, 0.45, 0.45]\n",
    "std = [0.225, 0.225, 0.225]\n",
    "num_frames = 64\n",
    "sampling_rate = 2\n",
    "frames_per_second = 30\n",
    "slowfast_alpha = 4\n",
    "num_clips = 10\n",
    "num_crops = 3\n",
    "\n",
    "class PackPathway(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Transform for converting video frames as a list of tensors. \n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, frames: torch.Tensor):\n",
    "        fast_pathway = frames\n",
    "        # Perform temporal sampling from the fast pathway.\n",
    "        slow_pathway = torch.index_select(\n",
    "            frames,\n",
    "            1,\n",
    "            torch.linspace(\n",
    "                0, frames.shape[1] - 1, frames.shape[1] // slowfast_alpha\n",
    "            ).long(),\n",
    "        )\n",
    "        frame_list = [slow_pathway, fast_pathway]\n",
    "        return frame_list\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def make_circle(js, idx, img=None):\n",
    "    x_list = []\n",
    "    y_list = []\n",
    "    color = []\n",
    "    dat = js.get('sequence').get('2d_pos')[idx]\n",
    "    bbox = js.get('sequence').get('bounding_box')[idx]\n",
    "    x1, y1, x2, y2 = float(bbox[0]), float(bbox[1]), float(bbox[2]), float(bbox[3])\n",
    "    for i in range(len(dat)):\n",
    "        if i % 3 == 0:\n",
    "            x_list.append(int(float(dat[i]) - x1))\n",
    "        elif i % 3 == 1:\n",
    "            y_list.append(int(float(dat[i]) - y1))\n",
    "        else:\n",
    "            if int(dat[i]) == 0:\n",
    "                color.append((0, 0, 255))\n",
    "            else:\n",
    "                color.append((255, 0, 0))\n",
    "    if img is None:\n",
    "        img = np.zeros((int(y2-y1), int(x2-x1), 3), np.uint8) + 255\n",
    "    for j in range(len(x_list)):\n",
    "        img = cv2.circle(img, (x_list[j],y_list[j]), 2, color[j], 5)\n",
    "\n",
    "    return img\n",
    "        "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "class ActionDataset(Dataset):\n",
    "    def __init__(self, file, interval=sampling_rate, max_len=num_frames, transform=None, train=True, mode=\"image\"):\n",
    "        super().__init__()\n",
    "        self.file = file\n",
    "        self.len = len(self.file)\n",
    "        self.interval = interval\n",
    "        self.max_len = max_len\n",
    "        self.transform = transform\n",
    "        self.train = train\n",
    "        self.datalayer = PackPathway()\n",
    "        self.mode = mode\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        file = self.file[idx]\n",
    "        imageFolder = sorted(glob2.glob(file + \"/*.jpg\"))\n",
    "        folderName = file.split(\"/\")[-1]\n",
    "        jsonFile = file +  \"/\" + folderName + \".json\"\n",
    "        with open(jsonFile, \"rb\") as f:\n",
    "            js = json.load(f)  \n",
    "        label = None\n",
    "        if \"action\" in js:\n",
    "            label = js[\"action\"] \n",
    "            if folderName == \"file_33\":\n",
    "                label = 5\n",
    "            label = torch.as_tensor(label, dtype=torch.long)\n",
    "\n",
    "        vid = []\n",
    "        for idx in range(len(js.get('sequence').get('2d_pos'))):\n",
    "            img = make_circle(js, idx, img=None)\n",
    "            vid.append(img)\n",
    "\n",
    "        trainImages = []\n",
    "        start = random.randint(0, len(imageFolder)-1-self.interval*self.max_len)\n",
    "        for i in range(start, start+self.interval*self.max_len):\n",
    "            if (i - start) % self.interval == 0:\n",
    "                if self.mode == \"image\":\n",
    "                    pil_image = Image.open(imageFolder[i])               \n",
    "                    arr = np.array(pil_image)       \n",
    "                else:\n",
    "                    arr = vid[i]\n",
    "                if self.transform:\n",
    "                    augmented = self.transform(image=arr) \n",
    "                    image = augmented['image']\n",
    "                trainImages.append(image)\n",
    "        C, H, W = image.shape\n",
    "        video = torch.stack(trainImages)\n",
    "        video = self._add_padding(video, self.max_len)\n",
    "        \n",
    "        frames = self.datalayer(video.permute(1,0,2,3))\n",
    "\n",
    "        return frames, label\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def _add_padding(self, video, max_len):\n",
    "        if video.shape[0] < max_len:\n",
    "            T, C, H, W = video.shape\n",
    "            pad = torch.zeros(max_len-T, C, H, W)\n",
    "            video = torch.cat([video, pad], dim=0)\n",
    "        else:\n",
    "            video = video[:max_len]\n",
    "\n",
    "        return video"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "class ActionTestDataset(Dataset):\n",
    "    def __init__(self, file, interval=sampling_rate, max_len=num_frames, transform=None, train=True, mode=\"image\"):\n",
    "        super().__init__()\n",
    "        self.file = file\n",
    "        self.len = len(self.file)\n",
    "        self.interval = interval\n",
    "        self.max_len = max_len\n",
    "        self.transform = transform\n",
    "        self.train = train\n",
    "        self.datalayer = PackPathway()\n",
    "        self.mode = mode\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        file = self.file[idx]\n",
    "        imageFolder = sorted(glob2.glob(file + \"/*.jpg\"))\n",
    "        folderName = file.split(\"/\")[-1]\n",
    "        jsonFile = file +  \"/\" + folderName + \".json\"\n",
    "        with open(jsonFile, \"rb\") as f:\n",
    "            js = json.load(f)  \n",
    "\n",
    "        label = None\n",
    "        if \"action\" in js:\n",
    "            label = js[\"action\"] \n",
    "            label = torch.as_tensor(label, dtype=torch.long)\n",
    "\n",
    "        vid = []\n",
    "        for idx in range(len(js.get('sequence').get('2d_pos'))):\n",
    "            img = make_circle(js, idx, img=None)\n",
    "            vid.append(img)\n",
    "\n",
    "        \n",
    "        videos = []\n",
    "        N = len(imageFolder)-1-self.interval*self.max_len\n",
    "        startRange = range(0, N, int(N//1))\n",
    "        for r in range(len(startRange)):\n",
    "            start = startRange[r]\n",
    "            trainImages = []\n",
    "            for i in range(start, start+self.interval*self.max_len):\n",
    "                if i % self.interval == 0:\n",
    "                    if self.mode == \"image\":\n",
    "                        pil_image = Image.open(imageFolder[i])               \n",
    "                        arr = np.array(pil_image)       \n",
    "                    else:\n",
    "                        arr = vid[i]\n",
    "                    if self.transform:\n",
    "                        augmented = self.transform(image=arr) \n",
    "                        image = augmented['image']\n",
    "                    trainImages.append(image)\n",
    "            video = torch.stack(trainImages)\n",
    "            video = self._add_padding(video, self.max_len)\n",
    "            frames = self.datalayer(video.permute(1,0,2,3))\n",
    "            videos.append(frames)\n",
    "            #####\n",
    "        #videos = torch.stack(videos)\n",
    "\n",
    "        return videos, _\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def _add_padding(self, video, max_len):\n",
    "        if video.shape[0] < max_len:\n",
    "            T, C, H, W = video.shape\n",
    "            pad = torch.zeros(max_len-T, C, H, W)\n",
    "            video = torch.cat([video, pad], dim=0)\n",
    "        else:\n",
    "            video = video[:max_len]\n",
    "\n",
    "        return video"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "def prepare_accuracy(output, label):\n",
    "    predict = torch.softmax(output, dim=-1).argmax(dim=-1).to(label.device)\n",
    "    return (predict==label).sum(), len(label)\n",
    "\n",
    "\n",
    "def inference_data(data, model):\n",
    "    data_logit = []\n",
    "    for i in range(len(data)):\n",
    "        with torch.no_grad():\n",
    "            sframes = []\n",
    "            fframes = []\n",
    "            sframes.append(data[i][0])\n",
    "            fframes.append(data[i][1])\n",
    "            x = [torch.stack(sframes), torch.stack(fframes)]\n",
    "            x = [j.to(device)[...] for j in x]\n",
    "            logit, _ = model(x, label=None)\n",
    "            data_logit.append(logit)\n",
    "\n",
    "    return torch.stack(data_logit)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "if not os.path.exists(\"model_weights\"):\n",
    "    os.mkdir(\"model_weights\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "def train_func(train_type=\"1\", mode=\"image\"):\n",
    "\n",
    "    if train_type == \"1\" or train_type == \"3\":\n",
    "        side_size = 224\n",
    "    elif train_type == \"2\" or train_type == \"4\":\n",
    "        side_size = 256\n",
    "\n",
    "    if train_type == \"1\" or train_type == \"2\":\n",
    "        path = \"cropped_train/\"\n",
    "    elif train_type == \"3\" or train_type == \"4\":\n",
    "        path = \"cropped_train2/\"\n",
    "   \n",
    "    if not os.path.exists(args.save_path): os.mkdir(args.save_path)\n",
    "    videoFolder = sorted(glob2.glob(path + \"*\"))\n",
    "\n",
    "    trainVideo = []\n",
    "    validVideo = []\n",
    "    validList = []\n",
    "    for i in range(len(videoFolder)):\n",
    "        if int(videoFolder[i].split(\"_\")[-1]) in validList:\n",
    "            validVideo.append(videoFolder[i])\n",
    "        else:\n",
    "            trainVideo.append(videoFolder[i])\n",
    "\n",
    "    albumentations_traintransform = albumentations.Compose([\n",
    "        albumentations.Resize(side_size , side_size), \n",
    "        albumentations.Normalize(mean, std),\n",
    "        albumentations.pytorch.transforms.ToTensorV2()\n",
    "    ])\n",
    "\n",
    "    albumentations_transform = albumentations.Compose([\n",
    "        albumentations.Resize(side_size , side_size), \n",
    "        albumentations.Normalize(mean, std),\n",
    "        albumentations.pytorch.transforms.ToTensorV2()\n",
    "    ])\n",
    "\n",
    "    trainDataset = ActionDataset(trainVideo, transform=albumentations_traintransform, mode=mode)\n",
    "    validDataset = ActionDataset(validVideo, transform=albumentations_transform, mode=mode)\n",
    "    trainLoader = DataLoader(trainDataset, batch_size=args.batch_size, num_workers=args.num_workers, shuffle=True)\n",
    "    validLoader = DataLoader(validDataset, batch_size=args.batch_size, num_workers=args.num_workers, shuffle=False)\n",
    "\n",
    "\n",
    "    net = pyvideo.slowfast.slowfast_16x8_r101_50_50()\n",
    "    modelPath = \"SLOWFAST_16x8_R101_50_50.pyth\"\n",
    "    net.load_state_dict(torch.load(modelPath)[\"model_state\"])\n",
    "\n",
    "    device = \"cuda\"\n",
    "    model = ActionBasicModule(device, net=net)\n",
    "    model = model.to(device)\n",
    "    x = trainDataset[0][0]\n",
    "    x = [i.to(device)[None, ...] for i in x]\n",
    "    out = model(x, label=None)\n",
    "    print(out[0])\n",
    "\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(\n",
    "            nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "        {'params': [p for n, p in param_optimizer if any(\n",
    "            nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "    ]\n",
    "    optimizer = AdamW(optimizer_grouped_parameters,\n",
    "                        lr=args.lr, correct_bias=False)\n",
    "\n",
    "    train_len = len(trainLoader.dataset)\n",
    "    print(f'data length {train_len}')\n",
    "    num_train_steps = int(train_len / (args.batch_size * args.num_workers) * args.max_epochs)\n",
    "    print(f'num_train_steps : {num_train_steps}')\n",
    "    num_warmup_steps = int(num_train_steps * args.warmup_ratio)\n",
    "    print(f'num_warmup_steps : {num_warmup_steps}')\n",
    "    scheduler = get_cosine_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=num_warmup_steps, num_training_steps=num_train_steps)\n",
    "\n",
    "    for epoch in range(args.max_epochs):\n",
    "        total_loss = 0\n",
    "        model.train()\n",
    "        print(\"------------TRAIN------------\")\n",
    "        for i, d in enumerate(tqdm(trainLoader)):  \n",
    "            data, label = d\n",
    "            x = [i.to(device)[...] for i in data]\n",
    "            optimizer.zero_grad()\n",
    "            output, loss = model(x, label, loss_mode=\"smoothing\")\n",
    "            total_loss += loss \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "        print(\"EPOCH:\", epoch)\n",
    "        print(\"train_loss:{:.6f}\".format(total_loss/len(trainLoader)))   \n",
    "\n",
    "        total_loss = 0\n",
    "        total_answer = 0\n",
    "        \n",
    "        model.eval()\n",
    "\n",
    "        if epoch == 26:\n",
    "            torch.save(\n",
    "                    model.state_dict(),\n",
    "                    args.save_path + f\"/modeltype{train_type}_{mode}_26Epoch.pth\"\n",
    "                    )\n",
    "\n",
    "        if epoch == 19:\n",
    "            torch.save(\n",
    "                    model.state_dict(),\n",
    "                    args.save_path + f\"/modeltype{train_type}_{mode}_19Epoch.pth\"\n",
    "                    )\n",
    "\n",
    "        \"\"\"if epoch == 49:\n",
    "            torch.save(\n",
    "                    model.state_dict(),\n",
    "                    args.save_path + f\"/modeltype{train_type}_{mode}_49Epoch.pth\"\n",
    "                    )\"\"\"\n",
    "                    \n",
    "    \n",
    "        \n",
    "    \n",
    "    \n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "train_func(train_type=\"1\", mode=\"image\")\n",
    "train_func(train_type=\"2\", mode=\"image\")\n",
    "train_func(train_type=\"4\", mode=\"image\")\n",
    "train_func(train_type=\"2\", mode=\"pose\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[ 0.0572, -0.1228,  0.0215, -0.0713, -0.0927, -0.2712]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward>)\n",
      "data length 142\n",
      "num_train_steps : 2130\n",
      "num_warmup_steps : 426\n",
      "------------TRAIN------------\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ada10d56db304acfa9c8c8e8a6b9c13f"
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=36), HTML(value='')))"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "EPOCH: 0\n",
      "train_loss:1.796589\n",
      "------------TEST------------\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7f9cb622cd2d46ea878c2902a98a12dc"
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=45), HTML(value='')))"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "./test\\file_142\n",
      "./test\\file_143\n",
      "./test\\file_146\n",
      "./test\\file_147\n",
      "./test\\file_148\n",
      "./test\\file_150\n",
      "./test\\file_151\n",
      "./test\\file_152\n",
      "./test\\file_153\n",
      "./test\\file_157\n",
      "./test\\file_159\n",
      "./test\\file_160\n",
      "./test\\file_161\n",
      "./test\\file_165\n",
      "./test\\file_166\n",
      "./test\\file_167\n",
      "./test\\file_168\n",
      "./test\\file_169\n",
      "./test\\file_171\n",
      "./test\\file_172\n",
      "./test\\file_173\n",
      "./test\\file_175\n",
      "./test\\file_176\n",
      "./test\\file_177\n",
      "./test\\file_179\n",
      "./test\\file_180\n",
      "./test\\file_181\n",
      "./test\\file_182\n",
      "./test\\file_183\n",
      "./test\\file_185\n",
      "FinalScore 12.280453825968237\n",
      "ACC 0.3333333333333333\n",
      "------------TRAIN------------\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0bb2cf594cc444be8dadd87d44229f2d"
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=36), HTML(value='')))"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "EPOCH: 1\n",
      "train_loss:1.623099\n",
      "------------TEST------------\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "40bd726b06e44a5a8e5a553174806748"
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=45), HTML(value='')))"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "./test\\file_143\n",
      "./test\\file_146\n",
      "./test\\file_147\n",
      "./test\\file_148\n",
      "./test\\file_150\n",
      "./test\\file_152\n",
      "./test\\file_159\n",
      "./test\\file_165\n",
      "./test\\file_167\n",
      "./test\\file_168\n",
      "./test\\file_169\n",
      "./test\\file_170\n",
      "./test\\file_171\n",
      "./test\\file_175\n",
      "./test\\file_176\n",
      "./test\\file_177\n",
      "./test\\file_180\n",
      "FinalScore 6.958923830382003\n",
      "ACC 0.6222222222222222\n",
      "------------TRAIN------------\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d0dc5f90b111467f86f805fc0311753d"
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=36), HTML(value='')))"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def test(train_type, mode, weight=\"bestLoss\"):\n",
    "    if train_type == \"1\" or train_type == \"3\":\n",
    "        side_size = 270\n",
    "    elif train_type == \"2\" or train_type == \"4\":\n",
    "        side_size = 256\n",
    "\n",
    "    if train_type == \"1\" or train_type == \"2\":\n",
    "        path = \"cropped_test/\"\n",
    "    elif train_type == \"3\" or train_type == \"4\":\n",
    "        path = \"cropped_test2/\"\n",
    "\n",
    "    albumentations_transform = albumentations.Compose([\n",
    "        albumentations.Resize(side_size , side_size), \n",
    "        albumentations.Normalize(mean, std),\n",
    "        albumentations.pytorch.transforms.ToTensorV2()\n",
    "    ])\n",
    "\n",
    "    testVideo = sorted(glob2.glob(path + \"*\"))\n",
    "    testDataset = ActionTestDataset(testVideo, transform=albumentations_transform, mode=mode)\n",
    "    testLoader = DataLoader(testDataset, batch_size=1, num_workers=args.num_workers, shuffle=False)\n",
    "\n",
    "    net = pyvideo.slowfast.slowfast_16x8_r101_50_50()\n",
    "    modelPath = \"SLOWFAST_16x8_R101_50_50.pyth\"\n",
    "    net.load_state_dict(torch.load(modelPath)[\"model_state\"])\n",
    "\n",
    "    device = \"cuda\"\n",
    "    model = ActionBasicModule(device, net=net)\n",
    "    model = model.to(device)\n",
    "    model.load_state_dict(torch.load(args.save_path + f\"/modeltype{train_type}_{mode}_{weight}.pth\"))\n",
    "    model.eval()\n",
    "\n",
    "    if not os.path.exists(\"submission\"):\n",
    "        os.mkdir(\"submission\")\n",
    "    print(\"------------TEST------------\")    \n",
    "    logits = torch.ones(len(testDataset), 6) * 0.000\n",
    "    for i in tqdm(range(len(testDataset))):\n",
    "        with torch.no_grad():\n",
    "            data, _ = testDataset[i]\n",
    "            logit = inference_data(data, model)\n",
    "            prob = torch.softmax(logit, dim=-1)\n",
    "            prob = torch.mean(prob, dim=0)\n",
    "            ### Extreme 1\n",
    "            index = prob.argmax(dim=-1)\n",
    "            logits[i] = prob #1.\n",
    "    logits =  logits.tolist()\n",
    "    probability = np.array(logits)\n",
    "    submission = pd.read_csv(\"sample_submission.csv\")\n",
    "    for i in range(6):\n",
    "        submission[f'Label_{i}'] = probability[:, i]\n",
    "    test_label = {}\n",
    "    for i in range(len(submission)):\n",
    "        f = submission.iloc[i]\n",
    "        filename = f[\"file_path\"]\n",
    "        test_label[filename] = labels[int(filename.split(\"_\")[-1])]\n",
    "\n",
    "    submission.to_csv(f\"submission/modeltype{train_type}_{mode}_{weight}.csv\", index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "t = [\"26Epoch\", \"19Epoch\"]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for k in t:\n",
    "    test(\"1\", \"image\", k)\n",
    "    test(\"2\", \"image\", k)\n",
    "    test(\"4\", \"image\", k)\n",
    "    if k in [\"19Epoch\"]:\n",
    "        test(\"2\", \"pose\", k)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "------------TEST------------\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7d580ab54c3e4693a8d3b39933ea93f2"
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=45), HTML(value='')))"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "------------TEST------------\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "43f7d9d57e5a4d8299f04b0fee84673e"
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=45), HTML(value='')))"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "------------TEST------------\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "782093ea4efa41148a8f16781ee404cb"
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=45), HTML(value='')))"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "------------TEST------------\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "50eb6c68dd56404e9e791bda7b15ef4e"
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=45), HTML(value='')))"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "------------TEST------------\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3405a3fb389d403fb2e78aebe7c7d8bb"
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=45), HTML(value='')))"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "------------TEST------------\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5e2cbd643e0f4177b6b1c18771e14c78"
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=45), HTML(value='')))"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "------------TEST------------\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1ac59c9fb139454d86620e4c55ba5401"
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=45), HTML(value='')))"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "------------TEST------------\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5d3f5d9cfbd74b1ea577b0990d736e4e"
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=45), HTML(value='')))"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "subs = sorted(glob2.glob(\"submission/*\"))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "submission = pd.read_csv(\"sample_submission.csv\")\n",
    "for i in range(6):\n",
    "    ans = pd.read_csv(subs[0])[f\"Label_{i}\"]\n",
    "    for j in range(1, len(subs)):\n",
    "        ans += pd.read_csv(subs[j])[f\"Label_{i}\"]\n",
    "    submission[f'Label_{i}'] = list(ans/len(subs))\n",
    "    \n",
    "submission2 = pd.read_csv(\"sample_submission.csv\")\n",
    "new_prob = np.zeros((len(submission), 6))\n",
    "for i in range(len(submission)):\n",
    "    f = submission.iloc[i]\n",
    "    prob = np.array([f[\"Label_0\"], f[\"Label_1\"], f[\"Label_2\"], f[\"Label_3\"], f[\"Label_4\"], f[\"Label_5\"]])\n",
    "    index = prob.argmax(axis=-1)\n",
    "    new_prob[i][index] = 1.\n",
    "\n",
    "for i in range(6):\n",
    "     submission2[f'Label_{i}'] = new_prob[:, i]\n",
    "\n",
    "submission2.to_csv(\"final_result.csv\", index=False)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "list index out of range",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-04ec58d5aa75>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msubmission\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../sample_submission.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf\"Label_{i}\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mans\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf\"Label_{i}\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def metric(submission, labels=labels):\n",
    "\n",
    "    test_label = {}\n",
    "    for i in range(len(submission)):\n",
    "        f = submission.iloc[i]\n",
    "        filename = f[\"file_path\"]\n",
    "        test_label[filename] = labels[int(filename.split(\"_\")[-1])]\n",
    "\n",
    "    log_loss = 0\n",
    "    acc = []\n",
    "    for i in range(len(submission)):\n",
    "        f = submission.iloc[i]\n",
    "        filename = f['file_path']\n",
    "        label = test_label[filename]\n",
    "        score = f[f\"Label_{label}\"]\n",
    "        log_loss -= math.log(score+1e-8)\n",
    "        #print(\"file\", filename)\n",
    "        #print(\"score\", score)\n",
    "        #print(\"logLoss\", -math.log(score+1e-8))\n",
    "        prob = np.array([f.Label_0, f.Label_1, f.Label_2, f.Label_3, f.Label_4, f.Label_5])\n",
    "        if int(np.argmax(prob)) == int(label):\n",
    "            acc.append(filename)\n",
    "\n",
    "    print(\"FinalScore\", log_loss / len(submission))\n",
    "    print(\"ACC\", len(acc)/len(submission))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "metric(submission2)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "FinalScore 1.228045373596824\n",
      "ACC 0.9333333333333333\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "98b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}