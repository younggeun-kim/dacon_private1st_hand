{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "!pip install fvcore\n",
    "!pip install albumentations\n",
    "!pip install albumentations.pytorch\n",
    "!pip install transformers"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import torch\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import glob2\n",
    "import cv2\n",
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from argparse import Namespace\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, IterableDataset\n",
    "import albumentations\n",
    "import albumentations.pytorch\n",
    "from transformers.optimization import AdamW, get_cosine_schedule_with_warmup\n",
    "from transformers import set_seed\n",
    "import pytorchvideo.models.hub as pyvideo\n",
    "!nvidia-smi\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"0\"\n",
    "\n",
    "\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Tue Oct 19 10:25:21 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.80.02    Driver Version: 450.80.02    CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-PCIE...  Off  | 00000000:18:00.0 Off |                    0 |\n",
      "| N/A   34C    P0    36W / 250W |   1181MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-PCIE...  Off  | 00000000:AF:00.0 Off |                    0 |\n",
      "| N/A   53C    P0    45W / 250W |      4MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "random_seed = 42\n",
    "set_seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed_all(random_seed) # if use multi-GPU\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(random_seed)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "opt = {\n",
    "    \"batch_size\": 4,\n",
    "    \"num_workers\": 1,\n",
    "    \"lr\": 5e-5,\n",
    "    \"max_epochs\": 51,\n",
    "    \"warmup_ratio\": 0.2,\n",
    "    \"print_step\": 100,\n",
    "    \"save_path\": \"model_weights\",\n",
    "} \n",
    "args = Namespace(**opt)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "class LabelSmoothingLoss(nn.Module):\n",
    "    def __init__(self, classes, smoothing=0.0, dim=-1):\n",
    "        super(LabelSmoothingLoss, self).__init__()\n",
    "        self.confidence = 1.0 - smoothing\n",
    "        self.smoothing = smoothing\n",
    "        self.cls = classes\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        pred = pred.log_softmax(dim=self.dim)\n",
    "        with torch.no_grad():\n",
    "            # true_dist = pred.data.clone()\n",
    "            true_dist = torch.zeros_like(pred)\n",
    "            true_dist.fill_(self.smoothing / (self.cls - 1))\n",
    "            true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
    "        return torch.mean(torch.sum(-true_dist * pred, dim=self.dim))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "class ActionBasicModule(nn.Module):\n",
    "    def __init__(self, device=\"cpu\", net=None):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.model = net\n",
    "        self.model.blocks[6].proj = nn.Linear(self.model.blocks[6].proj.in_features, 6, bias=True)\n",
    "        #self.model = self.model.to(self.device)\n",
    "        \n",
    "\n",
    "    def forward(self, x, label=None, loss_mode=\"smoothin\", smoothing=0.0):\n",
    "        x = self.model(x)\n",
    "        if label is not None:\n",
    "            if loss_mode == \"smoothing\":\n",
    "                lossFunc = LabelSmoothingLoss(6, smoothing=smoothing).to(self.device)\n",
    "            else:\n",
    "                lossFunc = nn.CrossEntropyLoss().to(self.device)\n",
    "            label = label.to(self.device)    \n",
    "            loss = lossFunc(x, label)\n",
    "            return x, loss\n",
    "        return x, _"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "device = \"cuda\"\n",
    "mean = [0.45, 0.45, 0.45]\n",
    "std = [0.225, 0.225, 0.225]\n",
    "num_frames = 64\n",
    "sampling_rate = 2\n",
    "frames_per_second = 30\n",
    "slowfast_alpha = 4\n",
    "num_clips = 10\n",
    "num_crops = 3\n",
    "\n",
    "class PackPathway(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Transform for converting video frames as a list of tensors. \n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, frames: torch.Tensor):\n",
    "        fast_pathway = frames\n",
    "        # Perform temporal sampling from the fast pathway.\n",
    "        slow_pathway = torch.index_select(\n",
    "            frames,\n",
    "            1,\n",
    "            torch.linspace(\n",
    "                0, frames.shape[1] - 1, frames.shape[1] // slowfast_alpha\n",
    "            ).long(),\n",
    "        )\n",
    "        frame_list = [slow_pathway, fast_pathway]\n",
    "        return frame_list\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "def make_circle(js, idx, img=None):\n",
    "    x_list = []\n",
    "    y_list = []\n",
    "    color = []\n",
    "    dat = js.get('sequence').get('2d_pos')[idx]\n",
    "    bbox = js.get('sequence').get('bounding_box')[idx]\n",
    "    x1, y1, x2, y2 = float(bbox[0]), float(bbox[1]), float(bbox[2]), float(bbox[3])\n",
    "    for i in range(len(dat)):\n",
    "        if i % 3 == 0:\n",
    "            x_list.append(int(float(dat[i]) - x1))\n",
    "        elif i % 3 == 1:\n",
    "            y_list.append(int(float(dat[i]) - y1))\n",
    "        else:\n",
    "            if int(dat[i]) == 0:\n",
    "                color.append((0, 0, 255))\n",
    "            else:\n",
    "                color.append((255, 0, 0))\n",
    "    if img is None:\n",
    "        img = np.zeros((int(y2-y1), int(x2-x1), 3), np.uint8) + 255\n",
    "    for j in range(len(x_list)):\n",
    "        img = cv2.circle(img, (x_list[j],y_list[j]), 2, color[j], 5)\n",
    "\n",
    "    return img\n",
    "        "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "class ActionDataset(Dataset):\n",
    "    def __init__(self, file, interval=sampling_rate, max_len=num_frames, transform=None, train=True, mode=\"image\"):\n",
    "        super().__init__()\n",
    "        self.file = file\n",
    "        self.len = len(self.file)\n",
    "        self.interval = interval\n",
    "        self.max_len = max_len\n",
    "        self.transform = transform\n",
    "        self.train = train\n",
    "        self.datalayer = PackPathway()\n",
    "        self.mode = mode\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        file = self.file[idx]\n",
    "        imageFolder = sorted(glob2.glob(file + \"/*.jpg\"))\n",
    "        folderName = file.split(\"/\")[-1]\n",
    "        jsonFile = file +  \"/\" + folderName + \".json\"\n",
    "        with open(jsonFile, \"rb\") as f:\n",
    "            js = json.load(f)  \n",
    "\n",
    "        \n",
    "        label = None\n",
    "        if \"action\" in js:\n",
    "            label = js[\"action\"] \n",
    "            if folderName == \"file_33\":\n",
    "                print(label)\n",
    "                label = 5\n",
    "            label = torch.as_tensor(label, dtype=torch.long)\n",
    "\n",
    "        vid = []\n",
    "        for idx in range(len(js.get('sequence').get('2d_pos'))):\n",
    "            img = make_circle(js, idx, img=None)\n",
    "            vid.append(img)\n",
    "\n",
    "        trainImages = []\n",
    "        start = random.randint(0, len(imageFolder)-1-self.interval*self.max_len)\n",
    "        for i in range(start, start+self.interval*self.max_len):\n",
    "            if (i - start) % self.interval == 0:\n",
    "                if self.mode == \"image\":\n",
    "                    pil_image = Image.open(imageFolder[i])               \n",
    "                    arr = np.array(pil_image)       \n",
    "                else:\n",
    "                    arr = vid[i]\n",
    "                if self.transform:\n",
    "                    augmented = self.transform(image=arr) \n",
    "                    image = augmented['image']\n",
    "                trainImages.append(image)\n",
    "        C, H, W = image.shape\n",
    "        video = torch.stack(trainImages)\n",
    "        video = self._add_padding(video, self.max_len)\n",
    "        \n",
    "        frames = self.datalayer(video.permute(1,0,2,3))\n",
    "\n",
    "        return frames, label\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def _add_padding(self, video, max_len):\n",
    "        if video.shape[0] < max_len:\n",
    "            T, C, H, W = video.shape\n",
    "            pad = torch.zeros(max_len-T, C, H, W)\n",
    "            video = torch.cat([video, pad], dim=0)\n",
    "        else:\n",
    "            video = video[:max_len]\n",
    "\n",
    "        return video"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "class ActionTestDataset(Dataset):\n",
    "    def __init__(self, file, interval=sampling_rate, max_len=num_frames, transform=None, train=True, mode=\"image\"):\n",
    "        super().__init__()\n",
    "        self.file = file\n",
    "        self.len = len(self.file)\n",
    "        self.interval = interval\n",
    "        self.max_len = max_len\n",
    "        self.transform = transform\n",
    "        self.train = train\n",
    "        self.datalayer = PackPathway()\n",
    "        self.mode = mode\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        file = self.file[idx]\n",
    "        imageFolder = sorted(glob2.glob(file + \"/*.jpg\"))\n",
    "        folderName = file.split(\"/\")[-1]\n",
    "        jsonFile = file +  \"/\" + folderName + \".json\"\n",
    "        with open(jsonFile, \"rb\") as f:\n",
    "            js = json.load(f)  \n",
    "\n",
    "        label = None\n",
    "        if \"action\" in js:\n",
    "            label = js[\"action\"] \n",
    "            label = torch.as_tensor(label, dtype=torch.long)\n",
    "\n",
    "        vid = []\n",
    "        for idx in range(len(js.get('sequence').get('2d_pos'))):\n",
    "            img = make_circle(js, idx, img=None)\n",
    "            vid.append(img)\n",
    "\n",
    "        \n",
    "        videos = []\n",
    "        N = len(imageFolder)-1-self.interval*self.max_len\n",
    "        startRange = range(0, N, int(N//1))\n",
    "        for r in range(len(startRange)):\n",
    "            start = startRange[r]\n",
    "            trainImages = []\n",
    "            for i in range(start, start+self.interval*self.max_len):\n",
    "                if i % self.interval == 0:\n",
    "                    if self.mode == \"image\":\n",
    "                        pil_image = Image.open(imageFolder[i])               \n",
    "                        arr = np.array(pil_image)       \n",
    "                    else:\n",
    "                        arr = vid[i]\n",
    "                    if self.transform:\n",
    "                        augmented = self.transform(image=arr) \n",
    "                        image = augmented['image']\n",
    "                    trainImages.append(image)\n",
    "            video = torch.stack(trainImages)\n",
    "            video = self._add_padding(video, self.max_len)\n",
    "            frames = self.datalayer(video.permute(1,0,2,3))\n",
    "            videos.append(frames)\n",
    "            #####\n",
    "        #videos = torch.stack(videos)\n",
    "\n",
    "        return videos, _\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def _add_padding(self, video, max_len):\n",
    "        if video.shape[0] < max_len:\n",
    "            T, C, H, W = video.shape\n",
    "            pad = torch.zeros(max_len-T, C, H, W)\n",
    "            video = torch.cat([video, pad], dim=0)\n",
    "        else:\n",
    "            video = video[:max_len]\n",
    "\n",
    "        return video"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "def prepare_accuracy(output, label):\n",
    "    predict = torch.softmax(output, dim=-1).argmax(dim=-1).to(label.device)\n",
    "    return (predict==label).sum(), len(label)\n",
    "\n",
    "\n",
    "def inference_data(data, model):\n",
    "    data_logit = []\n",
    "    for i in range(len(data)):\n",
    "        with torch.no_grad():\n",
    "            sframes = []\n",
    "            fframes = []\n",
    "            sframes.append(data[i][0])\n",
    "            fframes.append(data[i][1])\n",
    "            x = [torch.stack(sframes), torch.stack(fframes)]\n",
    "            x = [j.to(device)[...] for j in x]\n",
    "            logit, _ = model(x, label=None)\n",
    "            data_logit.append(logit)\n",
    "\n",
    "    return torch.stack(data_logit)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "if not os.path.exists(\"model_weights\"):\n",
    "    os.mkdir(\"model_weights\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "def train_func(train_type=\"1\", mode=\"image\"):\n",
    "\n",
    "    if train_type == \"1\" or train_type == \"3\":\n",
    "        side_size = 224\n",
    "    elif train_type == \"2\" or train_type == \"4\":\n",
    "        side_size = 256\n",
    "\n",
    "    if train_type == \"1\" or train_type == \"2\":\n",
    "        path = \"cropped_train/\"\n",
    "    elif train_type == \"3\" or train_type == \"4\":\n",
    "        path = \"cropped_train2/\"\n",
    "   \n",
    "    if not os.path.exists(args.save_path): os.mkdir(args.save_path)\n",
    "    videoFolder = sorted(glob2.glob(path + \"*\"))\n",
    "\n",
    "    trainVideo = []\n",
    "    validVideo = []\n",
    "    validList = []\n",
    "    for i in range(len(videoFolder)):\n",
    "        if int(videoFolder[i].split(\"_\")[-1]) in validList:\n",
    "            validVideo.append(videoFolder[i])\n",
    "        else:\n",
    "            trainVideo.append(videoFolder[i])\n",
    "\n",
    "    albumentations_traintransform = albumentations.Compose([\n",
    "        albumentations.Resize(side_size , side_size), \n",
    "        albumentations.Normalize(mean, std),\n",
    "        albumentations.pytorch.transforms.ToTensorV2()\n",
    "    ])\n",
    "\n",
    "    albumentations_transform = albumentations.Compose([\n",
    "        albumentations.Resize(side_size , side_size), \n",
    "        albumentations.Normalize(mean, std),\n",
    "        albumentations.pytorch.transforms.ToTensorV2()\n",
    "    ])\n",
    "\n",
    "    trainDataset = ActionDataset(trainVideo, transform=albumentations_traintransform, mode=mode)\n",
    "    validDataset = ActionDataset(validVideo, transform=albumentations_transform, mode=mode)\n",
    "    trainLoader = DataLoader(trainDataset, batch_size=args.batch_size, num_workers=args.num_workers, shuffle=True)\n",
    "    validLoader = DataLoader(validDataset, batch_size=args.batch_size, num_workers=args.num_workers, shuffle=False)\n",
    "\n",
    "\n",
    "    net = pyvideo.slowfast.slowfast_16x8_r101_50_50()\n",
    "    modelPath = \"SLOWFAST_16x8_R101_50_50.pyth\"\n",
    "    net.load_state_dict(torch.load(modelPath)[\"model_state\"])\n",
    "\n",
    "    device = \"cuda\"\n",
    "    model = ActionBasicModule(device, net=net)\n",
    "    model = model.to(device)\n",
    "    x = trainDataset[0][0]\n",
    "    x = [i.to(device)[None, ...] for i in x]\n",
    "    out = model(x, label=None)\n",
    "    print(out[0])\n",
    "\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(\n",
    "            nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "        {'params': [p for n, p in param_optimizer if any(\n",
    "            nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "    ]\n",
    "    optimizer = AdamW(optimizer_grouped_parameters,\n",
    "                        lr=args.lr, correct_bias=False)\n",
    "\n",
    "    train_len = len(trainLoader.dataset)\n",
    "    print(f'data length {train_len}')\n",
    "    num_train_steps = int(train_len / (args.batch_size * args.num_workers) * args.max_epochs)\n",
    "    print(f'num_train_steps : {num_train_steps}')\n",
    "    num_warmup_steps = int(num_train_steps * args.warmup_ratio)\n",
    "    print(f'num_warmup_steps : {num_warmup_steps}')\n",
    "    scheduler = get_cosine_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=num_warmup_steps, num_training_steps=num_train_steps)\n",
    "\n",
    "    for epoch in range(args.max_epochs):\n",
    "        total_loss = 0\n",
    "        model.train()\n",
    "        print(\"------------TRAIN------------\")\n",
    "        for i, d in enumerate(tqdm(trainLoader)):  \n",
    "            data, label = d\n",
    "            x = [i.to(device)[...] for i in data]\n",
    "            optimizer.zero_grad()\n",
    "            output, loss = model(x, label, loss_mode=\"smoothing\")\n",
    "            total_loss += loss \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            \n",
    "            #if i % args.print_step == 0:\n",
    "            #    print(\"step:\", i)\n",
    "            #    print(\"loss:{:.2f}\".format(loss.item()))\n",
    "        print(\"EPOCH:\", epoch)\n",
    "        print(\"train_loss:{:.6f}\".format(total_loss/len(trainLoader)))   \n",
    "\n",
    "        total_loss = 0\n",
    "        total_answer = 0\n",
    "        \n",
    "        model.eval()\n",
    "\n",
    "        torch.save(\n",
    "                    model.state_dict(),\n",
    "                    args.save_path + f\"/modeltype{train_type}_{mode}_lastEpoch.pth\"\n",
    "        )\n",
    "        if epoch == 21:\n",
    "            torch.save(\n",
    "                    model.state_dict(),\n",
    "                    args.save_path + f\"/modeltype{train_type}_{mode}_21Epoch.pth\"\n",
    "                    )\n",
    "\n",
    "        if epoch == 22:\n",
    "            torch.save(\n",
    "                    model.state_dict(),\n",
    "                    args.save_path + f\"/modeltype{train_type}_{mode}_22Epoch.pth\"\n",
    "                    )\n",
    "\n",
    "        if epoch == 23:\n",
    "            torch.save(\n",
    "                    model.state_dict(),\n",
    "                    args.save_path + f\"/modeltype{train_type}_{mode}_23Epoch.pth\"\n",
    "                    )\n",
    "\n",
    "        if epoch == 24:\n",
    "            torch.save(\n",
    "                    model.state_dict(),\n",
    "                    args.save_path + f\"/modeltype{train_type}_{mode}_24Epoch.pth\"\n",
    "                    )\n",
    "\n",
    "        if epoch == 25:\n",
    "            torch.save(\n",
    "                    model.state_dict(),\n",
    "                    args.save_path + f\"/modeltype{train_type}_{mode}_25Epoch.pth\"\n",
    "                    )\n",
    "        if epoch == 26:\n",
    "            torch.save(\n",
    "                    model.state_dict(),\n",
    "                    args.save_path + f\"/modeltype{train_type}_{mode}_26Epoch.pth\"\n",
    "                    )\n",
    "        if epoch == 27:\n",
    "            torch.save(\n",
    "                    model.state_dict(),\n",
    "                    args.save_path + f\"/modeltype{train_type}_{mode}_27Epoch.pth\"\n",
    "                    )\n",
    "\n",
    "        if epoch == 38:\n",
    "            torch.save(\n",
    "                    model.state_dict(),\n",
    "                    args.save_path + f\"/modeltype{train_type}_{mode}_38Epoch.pth\"\n",
    "                    )\n",
    "\n",
    "        if epoch == 39:\n",
    "            torch.save(\n",
    "                    model.state_dict(),\n",
    "                    args.save_path + f\"/modeltype{train_type}_{mode}_39Epoch.pth\"\n",
    "                    )\n",
    "\n",
    "        if epoch == 49:\n",
    "            torch.save(\n",
    "                    model.state_dict(),\n",
    "                    args.save_path + f\"/modeltype{train_type}_{mode}_49Epoch.pth\"\n",
    "                    )\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "train_func(train_type=\"2\", mode=\"image\")\n",
    "train_func(train_type=\"4\", mode=\"image\")\n",
    "train_func(train_type=\"4\", mode=\"pose\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[ 0.0572, -0.1228,  0.0215, -0.0713, -0.0927, -0.2712]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward>)\n",
      "data length 142\n",
      "num_train_steps : 71\n",
      "num_warmup_steps : 14\n",
      "------------TRAIN------------\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "af7515b5ab92474aa439e175f2790ad9"
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=36), HTML(value='')))"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n",
      "\n",
      "EPOCH: 0\n",
      "train_loss:1.652588\n",
      "------------TRAIN------------\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c0ffb5ee5d914c50a25b645448267cf5"
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=36), HTML(value='')))"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n",
      "\n",
      "EPOCH: 1\n",
      "train_loss:0.917328\n",
      "tensor([[-0.1780,  0.2425, -0.0184, -0.1840,  0.0207,  0.0008]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward>)\n",
      "data length 142\n",
      "num_train_steps : 71\n",
      "num_warmup_steps : 14\n",
      "------------TRAIN------------\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "34c7563b0c164d46ae5a6e7c741783be"
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=36), HTML(value='')))"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n",
      "\n",
      "EPOCH: 0\n",
      "train_loss:1.663127\n",
      "------------TRAIN------------\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2844beb6863f4c2c883346c1696fa9e4"
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=36), HTML(value='')))"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n",
      "\n",
      "EPOCH: 1\n",
      "train_loss:1.093969\n",
      "tensor([[-0.3621,  0.2744,  0.1845,  0.0023,  0.0237,  0.0271]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward>)\n",
      "data length 142\n",
      "num_train_steps : 71\n",
      "num_warmup_steps : 14\n",
      "------------TRAIN------------\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bfe545e993c7431b8e3e400eaf0ea123"
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=36), HTML(value='')))"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n",
      "\n",
      "EPOCH: 0\n",
      "train_loss:1.712861\n",
      "------------TRAIN------------\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5e318c9a687543dc8deef7338d930ce4"
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=36), HTML(value='')))"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n",
      "\n",
      "EPOCH: 1\n",
      "train_loss:1.194058\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "def test(train_type, mode, weight=\"25Epoch\"):\n",
    "    if train_type == \"1\" or train_type == \"3\":\n",
    "        side_size = 224\n",
    "    elif train_type == \"2\" or train_type == \"4\":\n",
    "        side_size = 256\n",
    "\n",
    "    if train_type == \"1\" or train_type == \"2\":\n",
    "        path = \"cropped_test/\"\n",
    "    elif train_type == \"3\" or train_type == \"4\":\n",
    "        path = \"cropped_test2/\"\n",
    "\n",
    "    albumentations_transform = albumentations.Compose([\n",
    "        albumentations.Resize(side_size , side_size), \n",
    "        albumentations.Normalize(mean, std),\n",
    "        albumentations.pytorch.transforms.ToTensorV2()\n",
    "    ])\n",
    "\n",
    "    testVideo = sorted(glob2.glob(path + \"*\"))\n",
    "    testDataset = ActionTestDataset(testVideo, transform=albumentations_transform, mode=mode)\n",
    "    testLoader = DataLoader(testDataset, batch_size=1, num_workers=args.num_workers, shuffle=False)\n",
    "\n",
    "    net = pyvideo.slowfast.slowfast_16x8_r101_50_50()\n",
    "    modelPath = \"SLOWFAST_16x8_R101_50_50.pyth\"\n",
    "    net.load_state_dict(torch.load(modelPath)[\"model_state\"])\n",
    "\n",
    "    device = \"cuda\"\n",
    "    model = ActionBasicModule(device, net=net)\n",
    "    model = model.to(device)\n",
    "    model.load_state_dict(torch.load(args.save_path + f\"/modeltype{train_type}_{mode}_{weight}.pth\"))\n",
    "    model.eval()\n",
    "\n",
    "    if not os.path.exists(\"submission\"):\n",
    "        os.mkdir(\"submission\")\n",
    "    print(\"------------TEST------------\")    \n",
    "    logits = torch.ones(len(testDataset), 6) * 0.000\n",
    "    for i in tqdm(range(len(testDataset))):\n",
    "        with torch.no_grad():\n",
    "            data, _ = testDataset[i]\n",
    "            logit = inference_data(data, model)\n",
    "            prob = torch.softmax(logit, dim=-1)\n",
    "            prob = torch.mean(prob, dim=0)\n",
    "            ### Extreme 1\n",
    "            index = prob.argmax(dim=-1)\n",
    "            logits[i] = prob #1.\n",
    "    logits =  logits.tolist()\n",
    "    probability = np.array(logits)\n",
    "    submission = pd.read_csv(\"sample_submission.csv\")\n",
    "    for i in range(6):\n",
    "        submission[f'Label_{i}'] = probability[:, i]\n",
    "\n",
    "    submission.to_csv(f\"submission/modeltype{train_type}_{mode}_{weight}.csv\", index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "t = [\"21Epoch\", \"22Epoch\", \"23Epoch\", \"24Epoch\", \"25Epoch\", \"26Epoch\", \"27Epoch\", \"38Epoch\", \"39Epoch\", \"49Epoch\"]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "for k in t:  \n",
    "    if k in [\"21Epoch\", \"22Epoch\", \"23Epoch\", \"24Epoch\", \"25Epoch\", \"26Epoch\", \"27Epoch\"]:\n",
    "        test(\"4\", \"image\", k) \n",
    "    elif k in [\"39Epoch\"]:\n",
    "        test(\"4\", \"pose\", k)\n",
    "        test(\"4\", \"image\", k) \n",
    "    elif k in [\"38Epoch\", \"49Epoch\"]:\n",
    "        test(\"2\", \"image\", k)\n",
    "        test(\"4\", \"image\", k) \n",
    "\n",
    "    "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "------------TEST------------\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "277f4188b11b4fdeba5318fba288aacc"
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=45), HTML(value='')))"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "------------TEST------------\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ba6b44706a434cc3b292aca0a0c3929c"
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=45), HTML(value='')))"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "------------TEST------------\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a27016bf5c004401b62d211a6ed3de8d"
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=45), HTML(value='')))"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "------------TEST------------\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9554a1ce377f40afb3d8d15a74bb09c5"
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=45), HTML(value='')))"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "------------TEST------------\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2b6c071cc02a40b4938daeae97e45826"
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=45), HTML(value='')))"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "------------TEST------------\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e9899db62ca9417e91b4c163b6b74e1c"
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=45), HTML(value='')))"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "------------TEST------------\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b4c1ee79529e4c0e910feccaf727c434"
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=45), HTML(value='')))"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "------------TEST------------\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fece205c7228410eacbfd10a6e310dbc"
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=45), HTML(value='')))"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "------------TEST------------\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "db0d866e184b4b79afd2747099f289a5"
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=45), HTML(value='')))"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "------------TEST------------\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "523bb394245346c0ad693f140c78b8e0"
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=45), HTML(value='')))"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "------------TEST------------\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9a66eda2b95c457380ac6ce0e0339f79"
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=45), HTML(value='')))"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "------------TEST------------\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "291de6a724724bde80aba9cd4a008cdb"
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=45), HTML(value='')))"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "------------TEST------------\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b7e02f60b2914835aea7e1b2def9fa3b"
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=45), HTML(value='')))"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "subs = sorted(glob2.glob(\"submission/*\"))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "submission = pd.read_csv(\"sample_submission.csv\")\n",
    "for i in range(6):\n",
    "    ans = pd.read_csv(subs[0])[f\"Label_{i}\"]\n",
    "    for j in range(1, len(subs)):\n",
    "        ans += pd.read_csv(subs[j])[f\"Label_{i}\"]\n",
    "    submission[f'Label_{i}'] = list(ans/len(subs))\n",
    "    \n",
    "submission2 = pd.read_csv(\"sample_submission.csv\")\n",
    "new_prob = np.zeros((len(submission), 6))\n",
    "for i in range(len(submission)):\n",
    "    f = submission.iloc[i]\n",
    "    prob = np.array([f[\"Label_0\"], f[\"Label_1\"], f[\"Label_2\"], f[\"Label_3\"], f[\"Label_4\"], f[\"Label_5\"]])\n",
    "    index = prob.argmax(axis=-1)\n",
    "    new_prob[i][index] = 1.\n",
    "\n",
    "for i in range(6):\n",
    "     submission2[f'Label_{i}'] = new_prob[:, i]\n",
    "\n",
    "submission2.to_csv(\"final_result.csv\", index=False)  "
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "98b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}